---
title: 'Behavioral Economics Capstone: Memory Group'
author: "Donald Dinerman"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F) 
```

```{r, include = FALSE}
## Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(multcomp) #glht
library(readxl)
library(jtools) #summ
library(kableExtra)
library(gridExtra)
library(magick)
library(kableExtra) #kable()

# html tables for lm summary
library(sjPlot)
library(sjmisc)
library(sjlabelled)
```

# Experimental Design

**Industry Partners**

Minnesota Wild & New York Islanders (NHL Teams)

**Research Objective**

Using a behaviorally-informed approach to increase season ticket renewals.

**Behavioral Approach**

*Issue*

The emails sent out to season ticket holders are do not clearly convey the message that they should renew their tickets and the benefits are displayed sloppily in a matrix.

*Solution*

Modify the email format to concisely highlight the main message that season ticket holders should renew their tickets and to better showcase the benefits.

**Variables of Interest**

1. Benefit Memory Retention

2. Season Ticket Renewal Likelihood

3. Demographic Information (e.g., Age, Gender)

**Control**

Current Minnesota Wild email communications to season ticket holders.

```{r, echo = F}
#show image

im = image_read("C:/Temp One Drive/Capstone/Picture4.png")
image_trim(im)
```

**Treatments**

All treatments have the same concise messaging regarding season ticket renewals. The differences are how we design the benefits matrix.

1. Ranking: Organize the benefits by their rankings according to subjects' preferences.

```{r, echo = F}
#show image

im = image_read("C:/Temp One Drive/Capstone/Picture1.png")
image_trim(im)
```

2. Categorization: Create buckets relating the benefits while maintaining the ranking system within each bucket.

```{r, echo = F}
#show image

im = image_read("C:/Temp One Drive/Capstone/Picture2.png")
image_trim(im)
```

3. Reduced List: Display the 5 highest ranked benefits in a matrix.

```{r, echo = F}
#show image

im = image_read("C:/Temp One Drive/Capstone/Picture3.png")
image_trim(im)
```

**Experimental Survey Flow**

We designed our survey on Qualtrics and deployed it using MTurk.

```{r, echo = F}
#show image

im = image_read("C:/Temp One Drive/Capstone/Picture5.png")
image_trim(im)
```

# Pre-Test

Before our experimental survey, we conducted a pre-test survey to learn about our subject pool's preferences regarding season ticket benefits.

These preferences were then used to inform our benefits ranking system in our treatment email designs.

## Benefit Ranking

```{r}
#load data
df_pre_dummy = read.csv("Pretest_data.csv", skip = 1)

df_pre = read.csv("Presurvey_nov3.csv", skip = 1)
colnames(df_pre) = colnames(df_pre_dummy)
```

```{r}
#prep data
#colnames(df_pre)

df_pre_1 = df_pre[-1, c(3, 18, 22:27, 32:42)]

df_pre_2 = df_pre_1[,c(1:3, 9:19)]

df_pre_3 = filter(df_pre_2, Response.Type != "Survey Preview" & Sports.Filter != "0" & MTurk.ID. != "test")

df_pre_fin = df_pre_3 %>%
  pivot_longer(cols = 4:last_col(), names_to = "benefit", values_to = "rank")

df_pre_fin$rank = as.numeric(df_pre_fin$rank) #change class: ch to dbl

df_pre_fin$benefit = gsub("\\.", " ", df_pre_fin$benefit) #replace . with space
```

There are multiple ways to rank the pre-test benefits including using mean, median, or top 5 ranking counts.

We've settled on using top 5 ranking counts to inform how we order the pre-test benefits.

```{r,include=F}
#Mean ranking
df_pre_fin %>%
  group_by(benefit) %>%
  summarise(mean_count = round(mean(rank), 2)) %>%
  arrange(-mean_count) %>%
  mutate(ranking = 1:nrow(.))

#Median ranking
df_pre_fin %>%
  group_by(benefit) %>%
  summarise(median_count = round(median(rank), 2)) %>%
  arrange(-median_count) %>%
  mutate(ranking = 1:nrow(.))

#Top 3 ranking count
#Number of times a benefit is listed as someones top 3
df_pre_fin$top_three = ifelse(df_pre_fin$rank <= 3, 1, 0)

df_pre_fin %>%
  group_by(benefit) %>%
  summarise(top_three_count = sum(top_three)) %>%
  arrange(-top_three_count) %>%
  mutate(ranking = 1:nrow(.))
```

```{r}
#Top 5 ranking count
#Number of times a benefit is listed as someones top 5
df_pre_fin$top_five = ifelse(df_pre_fin$rank <= 5, 1, 0)

tab_1 = df_pre_fin %>%
  group_by(benefit) %>%
  summarise(top_five_count = sum(top_five)) %>%
  arrange(-top_five_count) %>%
  mutate(ranking = 1:nrow(.))

colnames(tab_1) = c("Benefit", "Top Five", "Ranking")

head(tab_1, 5) %>%
  kbl(caption = "Table 1: Top 5 Pre-Test Benefits", booktabs = T) %>% 
  kable_paper("hover", full_width = T)
```

# Experiment

## Data Prep

```{r}
#load data
df = read.csv("Memory Project_November 11, 2021_16.19_buffer_count.csv", header = T)
#colnames(df)
#head(df)
```

```{r}
#Remove first two rows
df_rem2 = df[-c(1:2),]

#filter based off of std criteria: actual respondents, sports filter, attention check

df_1 = filter(df_rem2, Status == "IP Address", MTurkID != "test", Sports_Filter != "0", attention_check_1 == "Other", 
              attention_check_2_1 == "70", attention_check_2_2 == "50")

#ch to dbl
df_1 = transform(df_1,
         Renewal.Liklihood_1 = as.numeric(Renewal.Liklihood_1), 
         label = as.factor(label))
```

```{r}
#change label names using case_when
temp = df_1$label
temp_unique = unique(temp)

df_1$label = case_when(
  temp == temp_unique[1] ~ "Reduced List",
  temp == temp_unique[2] ~ str_to_title(temp_unique[2]),
  temp == temp_unique[3] ~ str_to_title(temp_unique[3]),
  temp == temp_unique[4] ~ str_to_title(temp_unique[4])
)
```

```{r}
#Add benefit retention memory (%) variable
#Create list of benefits to find correct response proportion in data using grep
#add the two new fake benefits

benefit_list = c("4Ever Wild Rewards", "Discounted Wild Merchandise", "Interest Free Payment Plans", "Hockey Lodge Discount", 
                 "Purchase Additional Tickets at a Discounted Rate", "Member Events", "Stadium Tours", "Dedicated Account Manager",
                 "Playoff Access", "Right of First Refusal for Concerts and Events", "Options to Purchase Suites Using flex credit",
                 "Same Seat Guarantee", "Ticket Trade- switch out games you can't attend", "Complimentary Parking", 
                 "Gameday Travel Package", "Discounted Concessions", "Early Entry on Game Days", 
                 "Exclusive Conferences Calls with Players, Managers, and Front Office Executives", 
                 "Free Holiday Ornament", "Access to all streamed NHL Games", "Exclusive Restroom Access", "Autographed Merchandise")

real_benefits = c("4Ever Wild Rewards", "Interest Free Payment Plans", "Hockey Lodge Discount", 
                  "Purchase Additional Tickets at a Discounted Rate", "Member Events", "Dedicated Account Manager",
                  "Playoff Access", "Right of First Refusal for Concerts and Events",
                  "Same Seat Guarantee", "Ticket Trade- switch out games you can't attend", "Complimentary Parking")

fake_benefits = benefit_list[!benefit_list %in% real_benefits]

benefit_levels = c(real_benefits, fake_benefits)
```

```{r}
# if a string contains " Managers" add "Exclusive Conferences Calls with Players, Managers, and Front Office Executives" to list
# Remove "Exclusive Conferences Calls with Players", " Managers", " and Front Office Executives"

do_all_func = function(vec){
  
  list_temp = strsplit(vec, ",") #extract elements

  list_to_df = function(x){sapply(x, `length<-`, max(lengths(x))) %>% as.matrix() %>% as.data.frame()} #convert to df

  df_list =  list_to_df(list_temp)

  add_func = function(x){
  
    temp = " Managers" %in% x
  
    if(temp == T){
      prod = append(x[temp], "Exclusive Conferences Calls with Players, Managers, and Front Office Executives")}
    else{prod = x}
    prod
  }

  add_list = apply(df_list, MARGIN = 2, FUN = add_func) %>% list_to_df()

  #Removal

  drop_vec = c("Exclusive Conferences Calls with Players", " Managers", " and Front Office Executives")

  drop_func = function(x){
  
    x[x %in% drop_vec == F]
  }

  complete_list = apply(add_list, MARGIN = 2, FUN = drop_func) %>% list_to_df()
  complete_list
}

df_retention = do_all_func(df_1$Initial_Retention)

df_value = do_all_func(df_1$Valued_Retention)
```

```{r}
#Create data frame with subject on x and words on y, with counts in the cells (1,0)

binary_table = function(df){
  
  test = function(x){
    xy = table(factor(x, levels = benefit_levels)) %>% data.frame()
    colnames(xy) = c("benefits", "count")

    pivot_wider(xy, names_from = benefits, values_from = count)
  }

  hold = NULL

  for(i in 1:ncol(df)){
    temp = test(df[,i])
    hold = rbind(hold, temp)
  }

  hold
}

mat_retention = binary_table(df_retention)
mat_value = binary_table(df_value)
```

```{r}
#next step: create proportion of correct responses, proportion of total retention/value
#can cbind label/treatment information post: cbind(df, label = df_1$label)
#set the factor levels so that the first 11 match the first 11 real benefits and the remaining match the fake benefits (done)
#add two false benefits: create a memory score --> +1 for correct answer, -1 for incorrect answer

#false recall: # times F vs # T times

prep_rep_func = function(mat_retention){
  
n_attempts = apply(mat_retention, 1, sum) #sum across rows w binary entries to get total attempts

mat_retention$T_num = apply(mat_retention[,1:11], 1, sum) #sum T across rows

mat_retention$F_num = apply(mat_retention[,12:22], 1, sum) #sum F across rows

mat_retention$memory_score = mat_retention$T_num - mat_retention$F_num #memory score

mat_retention_fin = cbind(label = df_1$label, n_attempts, mat_retention)

#add payment col: payment is +$0.05 for correct & -$0.05 for false (floor at zero)

mat_retention_fin$user_payment = mat_retention_fin$memory_score * 0.05

mat_retention_fin$user_payment = ifelse(mat_retention_fin$user_payment < 0, 0, mat_retention_fin$user_payment)

#cbind renewal likelihood

mat_retention_fin_pre = cbind(mat_retention_fin, Renewal.Liklihood_1 = df_1$Renewal.Liklihood_1, Gender = df_1$Gender)
mat_retention_fin_pre
}

mat_retention_fin_pre = prep_rep_func(mat_retention)

mat_value_fin_pre = prep_rep_func(mat_value)
```

```{r}
#Timing var
#last click vs page submit

num_round = function(x){round(as.numeric(x), 2)}

#make timing numeric
df_1 = transform(df_1,
          Control_time_First.Click = num_round(Control_time_First.Click),
          Control_time_Last.Click = num_round(Control_time_Last.Click),
          Control_time_Page.Submit = num_round(Control_time_Page.Submit),
        
          Reduced_time_First.Click = num_round(Reduced_time_First.Click),
          Reduced_time_Last.Click = num_round(Reduced_time_Last.Click),
          Reduced_time_Page.Submit = num_round(Reduced_time_Page.Submit),
          
          Ranking_time_First.Click = num_round(Ranking_time_First.Click),
          Ranking_time_Last.Click = num_round(Ranking_time_Last.Click),
          Ranking_time_Page.Submit = num_round(Ranking_time_Page.Submit),
          
          Categorization_time_First.Click = num_round(Categorization_time_First.Click),
          Categorization_time_Last.Click = num_round(Categorization_time_Last.Click),
          Categorization_time_Page.Submit = num_round(Categorization_time_Page.Submit),
          
          Buffer_time_First.Click = num_round(Buffer_time_First.Click),
          Buffer_time_Last.Click = num_round(Buffer_time_Last.Click),
          Buffer_time_Page.Submit = num_round(Buffer_time_Page.Submit),
          
          Buffer_list_time_First.Click = num_round(Buffer_list_time_First.Click),
          Buffer_list_time_Last.Click = num_round(Buffer_list_time_Last.Click),
          Buffer_list_time_Page.Submit = num_round(Buffer_list_time_Page.Submit))

#Based on page submit
xx = paste(df_1$Control_time_Page.Submit, df_1$Reduced_time_Page.Submit, df_1$Ranking_time_Page.Submit, 
           df_1$Categorization_time_Page.Submit) %>%
  data.frame()

sub_NA = function(df){gsub("NA", "", df)}

time_clean_func = function(mat_retention_fin_pre){
  
mat_retention_fin_pre$page_time = apply(xx, 1, sub_NA) %>% as.numeric()

#Remove observations over 2 minutes (120 seconds) and under 3 seconds & add age variable

mat_retention_fin_1 = mat_retention_fin_pre %>% mutate(age = as.numeric(df_1$Age), buffer_count = df_1$Count, .before = n_attempts) %>% 
  filter(page_time >=3, page_time <= 120)

mat_retention_fin_1
}

mat_retention_fin_1 = time_clean_func(mat_retention_fin_pre)

mat_value_fin_1 = time_clean_func(mat_value_fin_pre)
```

```{r}
#Create Age Buckets
temp = mat_retention_fin_1$age
age_bucket = ifelse(temp >= 18 & temp <= 34, "18-34",
                    ifelse(temp >= 35 & temp <= 50, "35-50", "Older than 50"))

mat_retention_fin_1 = mat_retention_fin_1 %>% mutate(age_bucket = as.factor(age_bucket), .after = age)
```

```{r}
#proportion of correct responses over total buffer words
#mutate proportion into mat_retention_fin_1
n_buffer = 15 #number of buffer words
mat_retention_fin_1$prop_buffer = mat_retention_fin_1$buffer_count/n_buffer

#Group by buffer memory (median split)
temp = mat_retention_fin_1$prop_buffer
cutoff = median(temp)

mat_retention_fin_1 = mutate(mat_retention_fin_1, buffer_group = ifelse(temp >= cutoff, 1, 0) %>% as.factor(), .after = buffer_count)
```

## EDA

```{r}
tab_2 = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(n_subjects = n())

colnames(tab_2) = c("Condition", "Sample Size")

tab_2 %>%
  kbl(caption = "Table 2: Sample Size Across Conditions", booktabs = T) %>% 
  kable_paper("hover", full_width = T)
```

According to Table 2, we have a relatively robust and equal amount of subjects for each condition in our experiment.

### Memory

EDA for subjects' memory of the season ticket's benefits.

```{r, message=F, warning=F, fig.cap="Figure 1: Bar plot of average correct recollection across conditions."}
#Need to take proportion approach to account for limited choice set for the 'reduced list' treatment
#False/True: Total, Proportion
#new x: difference in proportions to control for diff in benefit options and n_attempts

#FALSE
mat_retention_fin_1 = mat_retention_fin_1 %>%
  mutate(prop_T = round(T_num/n_attempts, 3),
         prop_F = round(F_num/n_attempts, 3),
         prop_diff = prop_T-prop_F) 

position = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(False = mean(prop_F),
            sd = sd(prop_T, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>% 
  arrange(-False) %>%
  pull(1)

#TRUE
position = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(True = mean(prop_T),
            sd = sd(prop_T, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>% 
  arrange(-True) %>%
  pull(1)
  
mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(True = mean(prop_T)*100,
            sd = sd(prop_T*100, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>%
  pivot_longer(cols = True,
               names_to = "T_or_F",
               values_to = "Total") %>%
  ggplot(aes(x = label, y = Total)) +
  geom_col(position = "dodge", col = "black", fill = "steelblue") +
  geom_errorbar(aes(ymin = Total - CI, ymax= Total + CI), width = .2) +
  scale_x_discrete(limits = position[length(position):1]) +
  coord_flip() +
  labs(title = "Average Correct Recollection", x = "Condition", y = "Recollection Percentage (%)", 
       subtitle = "Error bars represent 95% confidence interval")
```

```{r, message=F, warning=F, include=F}
#False
mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(False = mean(prop_F)*100,
            sd = sd(prop_F*100, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>%
  pivot_longer(cols = False,
               names_to = "T_or_F",
               values_to = "Total") %>%
  ggplot(aes(x = label, y = Total)) +
  geom_col(position = "dodge", col = "black", fill = "steelblue") +
  geom_errorbar(aes(ymin = Total - CI, ymax= Total + CI), width = .2) +
  scale_x_discrete(limits = position[length(position):1]) +
  coord_flip() +
  labs(title = "Average False Recollection", x = "Condition", y = "Recollection Percentage (%)", 
       subtitle = "Error bars represent 95% confidence interval")
```

Participants in the reduced list have the greatest correct recollection (proportionally) across conditions. However, this finding is not statistically significant and is not necessarily novel considering these subjects are presented with less benefits they have to remember.

```{r, message=F, warning=F, fig.cap="Figure 2: Average correct recollection across conditions and grouped by buffer activity performance."}
# Suppress summarise info
options(dplyr.summarise.inform = FALSE)

#color by buffer median and group by condition
mat_retention_fin_1 %>%
  group_by(label, buffer_group) %>%
  summarise(mean_prop_T = mean(prop_T)) %>%
  ggplot(aes(x = label, y = 100*mean_prop_T, fill = buffer_group)) +
  geom_col(col = "black", position = "dodge") +
  labs(title = "Average Correct Recollection", x = "Condition", y = "True Recolection (%)", fill = "Buffer Memory")
```


```{r, message=F, warning=F, fig.cap="Figure 3: Average incorrect recollection across conditions and grouped by buffer activity performance."}
mat_retention_fin_1 %>%
  group_by(label, buffer_group) %>%
  summarise(mean_prop_F = mean(prop_F)) %>%
  ggplot(aes(x = label, y = 100*mean_prop_F, fill = buffer_group)) +
  geom_col(col = "black", position = "dodge") +
  labs(title = "Mean False Recollection", x = "Condition", y = "False Recolection (%)", fill = "Buffer Memory")
```

Subjects are grouped whether they are above or below the median memory performance on the buffer activity in figures 2 and 3.

Individuals performing above the median in the buffer test appear to have systemically higher true recollection than individuals performing above the median.

Individuals performing below the median in the buffer test appear to have systemically higher false recollection than individuals performing above the median.

These findings are relevant because they demonstrate that subjects with inherently better memory, determined by their buffer activity performance, have better recollection across all subject groups and vice versa.

### Timing

EDA of the amount of time subjects are spending looking at the emails in each of the 4 conditions.

```{r, message=F, warning=F, include=F}
#bar chart of mean timing colored by treatment

position = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(mean_time = mean(page_time)) %>%
  arrange(mean_time) %>%
  pull(1)

mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(mean_time = mean(page_time),
            sd = sd(page_time, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>%
  ggplot(aes(x = label, y = mean_time)) +
  geom_col(fill = "steelblue", col = "black") +
  geom_errorbar(aes(ymin = mean_time - CI, ymax= mean_time + CI), width = .2) +
  scale_x_discrete(limits = position) +
  coord_flip() +
  labs(title = "Average Time Spent On Email Across Conditions", x = "Conditions", y = "Average Time (Seconds)",
       subtitle = "Error bars represent 95% confidence interval")

ggplot(mat_retention_fin_1, aes(x = page_time, col = label)) +
  geom_density() +
  labs(title = "Distribution of Time Spent on Screen Across Conditions", x = "Screen Time (Seconds)", col = "Condition", y = "Density")

mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(median_time = median(page_time),
            sd =  sd(page_time, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1), # tend to 1.96 if sample size is big enough) %>%
            CI = t*se) %>%
  ggplot(aes(x = label, y = median_time)) +
  geom_col(fill = "steelblue", col = "black") +
  geom_errorbar(aes(ymin = median_time - CI, ymax= median_time + CI), width = .2) +
  scale_x_discrete(limits = position) +
  coord_flip() +
  labs(title = "Median Time Spent On Email Across Conditions", x = "Conditions", y = "Median Time (Seconds)",
       subtitle = "Error bars represent 95% confidence interval")
```


```{r, message=F, warning=F, fig.cap="Figure 4: Boxplot of email screen time across conditions."}
position = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(median_time = median(page_time)) %>%
  arrange(-median_time) %>%
  pull(1)

ggplot(mat_retention_fin_1) +
  geom_boxplot(aes(x = label, y = page_time), col = "black", fill = "steelblue", alpha = 0.3) +
  scale_x_discrete(limits = position) +
  labs(title = "Boxplot of Screen Times Across Conditions", x = "Condition", y = "Screen Time (Seconds)")
```

Screen time is not significantly different among the treatments and control but the reduced list email condition has the lowest average time spent on screen. This does not come as a surprise considering it contains 6 fewer benefits than the other conditions.

Also the control appears to have the highest screen time which may be attributed to its lack of clarity in displaying the benefits and its bulky text requesting season ticket renewals.

### Memory Score

EDA of memory score which is defined as the difference between correct and false benefit recollection. For instance, a subject that remembers 6 benefits correctly and 5 incorrectly will have a memory score of 1 (i.e., 6 - 5 = 1).

$Memory \space score =  \# \space correct \space responses - \# \space incorrect \space responses$

```{r, message=F, warning=F, fig.cap="Figure 5: Bar plot of average memory score across conditions."}
#plot in func as list

ms_plot_func = function(mat_retention_fin_1){
  
p1 = ggplot(mat_retention_fin_1, aes(x = memory_score, col = label)) +
  geom_density() +
  labs(title = "Distribution of Memory Retention Across Conditions", x = "Memory Score", col = "Condition", y = "Density")

#determine factor positioning
positions = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(mean_memory = mean(memory_score)) %>%
  arrange(-mean_memory) %>%
  pull(1)

#bar chart of memory score grouped by treatment
p2 = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(mean_memory = mean(memory_score),
            sd = sd(memory_score, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1), # tend to 1.96 if sample size is big enough) %>%
            CI = t*se) %>%
  ggplot(aes(x = label, y = mean_memory)) +
  geom_col(fill = "steelblue", col = "black") +
  geom_errorbar(aes(ymin = mean_memory - CI, ymax= mean_memory + CI), width = .2) +
  scale_x_discrete(limits = positions[length(positions):1]) + #reverse string
  coord_flip() +
  labs(title = "Average Memory Scores Across Conditions", x = "Condition", y = "Average Memory Score", 
       subtitle = "Error bars represent 95% confidence interval")

#boxplot of MS by condition
p3 = ggplot(mat_retention_fin_1) +
  geom_boxplot(aes(x = label, y = memory_score), col = "black", fill = "steelblue", alpha = 0.3) +
  scale_x_discrete(limits = positions) +
  labs(title = "Boxplot of Memory Scores Across Conditions", x = "Condition", y = "Average Memory Score")

#list(p1,p2,p3)
p2
}

ms_plot_func(mat_retention_fin_1)
```

Across groups there is no significant difference in memory scores (not including the reduced list condition). 

Note that the reduced list condition has a smaller memory score because it presents subjects with fewer benefits. This reduced choice set sets a smaller cap of their memory score relative to the other conditions.

### Renewal Likelihood

```{r, message=F, warning=F, fig.cap="Figure 6: Average renewal likelihoods across conditions."}
#RL density plot colored by condition
rl_plot_func = function(mat_retention_fin_1){
  
p1 = ggplot(mat_retention_fin_1, aes(x = (Renewal.Liklihood_1), col = label)) +
  geom_density() +
  labs(title = "Distribution of Renewal Liklihood Across Conditions", x = "Renewal Liklihood", y = "Density", col = "Conditions")

#determine factor positioning
positions = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1)) %>%
  arrange(-mean_renewal) %>%
  pull(1)

#bar chart of renewal likelihood grouped by treatment
p2 = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1),
            sd = sd(Renewal.Liklihood_1, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1), # tend to 1.96 if sample size is big enough) %>%
            CI = t*se) %>%
  ggplot(aes(x = label, y = mean_renewal)) +
  geom_col(fill = "steelblue", col = "black") +
  geom_errorbar(aes(ymin = mean_renewal - CI, ymax = mean_renewal + CI), width = .2) +
  scale_x_discrete(limits = positions[length(positions):1]) + #reverse string
  coord_flip() +
  labs(title = "Average Renewal Likelihoods Across Conditions", x = "Condition", y = "Average Renewal Likelihood (%)",
       subtitle = "Error bars represent 95% confidence interval")

#boxplot of RL by condition

positions = mat_retention_fin_1 %>%
  group_by(label) %>%
  summarise(median_renewal = median(Renewal.Liklihood_1)) %>%
  arrange(-median_renewal) %>%
  pull(1)

p3 = ggplot(mat_retention_fin_1) +
  geom_boxplot(aes(x = label, y = Renewal.Liklihood_1), col = "black", fill = "steelblue", alpha = 0.3) +
  scale_x_discrete(limits = positions) +
  labs(title = "Boxplot of Renewal Likelihoods Across Conditions", x = "Condition", y = "Average Renewal Likelihood (%)")

#list(p1,p2,p3)
p2
}

rl_plot_func(mat_retention_fin_1)
```

Although subjects in the categorization condition had the highest renewal likelihood, there is no statistically significant difference in renewal likelihoods across the conditions.

```{r, message=F, warning=F, include=F}
#memory vs renewal likelihood
#trying to visualize connection between memory score and renewal likelihood

mat_retention_fin_1 %>%
  group_by(h = as.factor(memory_score)) %>%
  summarise(med_renewal = median(Renewal.Liklihood_1), count = n()) %>%
  filter(., count >= 10) %>% #filter out small sample size
  ggplot(aes(x = h, y = med_renewal)) + 
  geom_col(col = "black", fill = "steelblue") + 
  coord_cartesian(ylim = c(60, 80)) +
  labs(title = "Median Renewal Likelihood Across Memory Scores", x = "Memory Score", y = "Median Renewal Likelihood (%)", 
       subtitle = "Filtered for observations n >= 10")

mat_retention_fin_1 %>%
  group_by(h = as.factor(memory_score)) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1), count = n()) %>%
  filter(., count >= 10) %>% #filter out small sample size
  ggplot(aes(x = h, y = mean_renewal)) + 
  geom_col(col = "black", fill = "steelblue") + 
  coord_cartesian(ylim = c(60, 80)) + #zoom in
  labs(title = "Mean Renewal Likelihood Across Memory Scores", x = "Memory Score", y = "Mean Renewal Likelihood (%)",
       subtitle = "Filtered for observations n >= 10")

ggplot(mat_retention_fin_1, aes(x = as.factor(memory_score), y = Renewal.Liklihood_1)) + 
  geom_col(fill = "steelblue") + 
  labs(title = "Cumulative Renewal Likelihood Across Memory Scores", x = "Memory Score", y = "Mean Renewal Likelihood (%)")

ggplot(mat_retention_fin_1, aes(x = as.factor(memory_score))) +
         geom_bar(fill = "steelblue", col = "black") +
  labs(title = "Distribution of Memory Scores Across Ages", y = "Count", x = "Memory Score")
```

```{r, fig.cap="Figure 7: Average renewal likelihood grouped by median benefits remembered."}
mat_retention_fin_1$median_memory = ifelse(mat_retention_fin_1$memory_score < median(mat_retention_fin_1$memory_score),
                                            "Below Median", "Above Median") %>% as.factor()

position = mat_retention_fin_1 %>%
  group_by(median_memory) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1),
            sd = sd(Renewal.Liklihood_1, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>% 
  arrange(-mean_renewal)

mat_retention_fin_1 %>%
  group_by(median_memory) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1),
            sd = sd(Renewal.Liklihood_1, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>%
  ggplot(aes(x = median_memory, y = mean_renewal)) +
    geom_col(position = "dodge", col = "black", fill = "steelblue") +
    geom_errorbar(aes(ymin = mean_renewal - CI, ymax= mean_renewal + CI), width = .2) +
    labs(title = "Average Renwal Likelihood by Benefits Remebered", x = "Benefits Remembered (Median Split)", 
         y = "Average Renewal Likelihood (%)", subtitle = "Error bars represent 95% confidence interval")
```

The top performing half (50%) of subjects in memory tend to have a larger renewal likelihood than the bottom half. This suggests that there may be a positive relationship between memory retention and renewal likelihoods that should be explored in the modeling section via regression analysis.

```{r, message=F, warning=F, include=F}
#Age Buckets
ggplot(mat_retention_fin_1, aes(x = memory_score)) +
         geom_density(aes(fill = age_bucket), alpha = 0.4) +
  labs(title = "Distribution of Memory Scores Across Ages", y = "Density", x = "Memory Score", fill = "Age Buckets")

mat_retention_fin_1 %>%
  group_by(age_bucket) %>%
  summarise(avg_renewal = mean(Renewal.Liklihood_1))
```


```{r, message=F, warning=F, fig.cap="Figure 8: Average Renewal Likelihood grouped by age."}
position = mat_retention_fin_1 %>%
  group_by(age_bucket) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1),
            sd = sd(Renewal.Liklihood_1, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>% 
  arrange(-mean_renewal) %>%
  pull(1)

mat_retention_fin_1 %>%
  group_by(age_bucket) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1),
            sd = sd(Renewal.Liklihood_1, na.rm = T),
            se = sd / sqrt(n()),
            alpha = 0.05,
            t = qt((1-alpha)/2 + .5, n()-1),   # tend to 1.96 if sample size is big enough
            CI = t*se) %>%
  ggplot(aes(x = age_bucket, y = mean_renewal)) +
    geom_col(position = "dodge", col = "black", fill = "steelblue") +
    geom_errorbar(aes(ymin = mean_renewal - CI, ymax= mean_renewal + CI), width = .2) +
    scale_x_discrete(limits = position) +
    coord_cartesian(ylim = c(30, 75)) + #zoom in
    labs(title = "Average Renewal Likelihood by Benefits Remebered", x = "Age Groups", 
         y = "Average Renewal Likelihood (%)", subtitle = "Error bars represent 95% confidence interval")
```

Subjects between 35-50 years appear to have a higher renewal likelihoods than other age groups. Although these differences do not appear to be statistically significant, they are worth exploring in the modeling section of the analysis.

```{r, include=F}
ggplot(mat_retention_fin_1, aes(x = as.factor(memory_score))) +
         geom_bar(aes(fill = age_bucket), col = "black", position = "dodge") +
  labs(title = "Distribution of Memory Scores Across Ages", y = "Count", x = "Memory Score", fill = "Age Buckets")

n_scores = mat_retention_fin_1 %>%
  group_by(memory_score) %>%
  summarise(count = n()) %>%
  filter(., count >= 10) %>%
  pull(1)

mat_retention_fin_1 %>% 
  filter(., memory_score %in% n_scores) %>% #"WHERE col IN vec" like SQL, ~ iterated or statement
  group_by(memory_score, age_bucket) %>%
  summarise(mean_renewal = mean(Renewal.Liklihood_1),
            count = n()) %>%
  ggplot(aes(x = as.factor(memory_score), y = mean_renewal, fill = age_bucket)) +
  geom_col(col = "black", position = "dodge") +
  coord_cartesian(ylim = c(20, 85)) + #zoom in
  labs(title = "Renewal Likelihood Across Memory Scores and Ages", y = "Average Renewal Likelihood (%)", 
       x = "Memory Score", fill = "Age Buckets")
```

```{r, include = F}
### Value

#Analysis of benefits that subjects remembered and value.

#Note: Our analysis, findings, and presentation mostly concerned benefit memory retention and its impact on season ticket renewals rather #than valued benefits.

#```{r, message=F, warning=F}
#memory score
#ms_plot_func(mat_value_fin_1)
#```

#```{r, message=F, warning=F}
#renewal likelihood

#rl_plot_func(mat_value_fin_1)
```

## Statistical Tests

### Analysis of Variance (ANOVA)

#### Memory Score

Analysis of season ticket benefit retention across treatment conditions.

```{r, message = F , warning=F, fig.cap = "Figure 9: Scatterplot of residuals and fitted values & QQ plot to test constant variance and normality assumptions for the ANOVA model."}
#Memory Score
# Compute the analysis of variance; null: all mean are equal across groups
#Should only compare != Reduced list groups for memory score

mat_retention_fin_1$label  = as.factor(mat_retention_fin_1$label)

mat_limited = mat_retention_fin_1 %>% filter(label != "Reduced List")

res.aov = aov(memory_score ~ label, data = mat_limited)

par(mfrow = c(1,2))

plot(res.aov,1)
plot(res.aov,2)
```

There is a violation of normality with the standard ANOVA testing with deviations at the tail of the diagnol in the QQ plot. So we must conduct specialty ANOVA tests that don't require this condition.

```{r, message = F , warning=F, include=F}
# Summary of the analysis
#summary(res.aov)

# Check Assumptions

#Equal Var: Failed
par(mfrow = c(1,2))

plot(res.aov,1) #can do boxplot instead
bartlett.test(memory_score ~ label, data = mat_limited) #null: all populations variances are equal

#Normality: Failed numerically but passes visually (iffy)
plot(res.aov,2)
shapiro.test(res.aov$residuals) #null is that data is normally dist

#ANOVA w unequal variance: Welch's ANOVA
#Finding: Significant difference in memory score across groups

oneway.test(memory_score ~ label,
  data = mat_limited,
  var.equal = F # assuming unequal variances
)
```

```{r, message = F , warning=F, fig.cap="Table 3: Dunnett linear hypotheses summary table."}
#Special Tests: Don't require normality but they do require equal var (homogeneity)

# Tukey HSD test:
post_test <- glht(res.aov,
  linfct = mcp(label = "Tukey")
)

# Dunnett Test:
mat_retention_fin_1$label  = relevel(mat_retention_fin_1$label, ref = "Control")

res.aov.new = aov(memory_score ~ label, data = mat_retention_fin_1)

post_test <- glht(res.aov.new,
  linfct = mcp(label = "Dunnett")
)

summary(post_test)
```
Table 3: Dunnett linear hypotheses summary table.

The specialty ANOVA test (Dunnett) suggests that there is a significant difference in memory scores between the control and reduced list. However, this finding is not meaningful considering that the reduced choice list in the treatment systemically reduces its memory score.

#### Renewal Likelihood

Analysis of mean likelihood of season ticket renewals across treatment conditions.

```{r, message = F , warning=F, fig.cap = "Figure 10: Scatterplot of residuals and fitted values & QQ plot to test constant variance and normality assumptions for the ANOVA model."}
#Renewal likelihood

#Issue there are outliers: is it sound to remove outliers at zero likelihood?
# Compute the analysis of variance
#res.aov = aov((Renewal.Liklihood_1)^2 ~ label, data = mat_retention_fin_1) square transformation

res.aov = aov((Renewal.Liklihood_1) ~ label, data = mat_retention_fin_1)

# Summary of the analysis
#summary(res.aov)

# Check Assumptions

#bartlett.test(Renewal.Liklihood_1 ~ label, data = mat_retention_fin_1) #null: all populations variances are equal
#shapiro.test(res.aov$residuals) #null is that data is normally dist

#Equal Var: Satisfied

par(mfrow = c(1,2))

plot(res.aov,1)

#Normality: Failed --> tried square transformation and it helped but didn't completely fix
plot(res.aov,2)
```

There is a clear violation of normality with strong deviations from the diagnol in the QQ plot so we must use specialty ANOVA tests that don't require this assumption.

```{r, message = F , warning=F,include=F}
#These versions don't need normality assumption
#kruskal.test(Renewal.Liklihood_1 ~ label, data = mat_retention_fin_1) #same shape dist: verified --> check density plot
```


```{r, message = F , warning=F, fig.cap="Table 4: Pairwise comparisons across conditions using Wilcoxon rank sum test with continuity correction."}
pairwise.wilcox.test(mat_retention_fin_1$Renewal.Liklihood_1, mat_retention_fin_1$label,
                 p.adjust.method = "BH") #no p-value correction, alt use "BH"
```
Table 4: Pairwise comparisons across conditions using Wilcoxon rank sum test with continuity correction.

The pairwise wilcoxon rank sum test suggests that there is not a statistically significant difference in renewal likelihoods across conditions.

### Regression Model

Alternatively to an ANOVA model, we can build a regression model to control for explanatory variables that may influence the effect of memory on renewal likelihood.

The following is the linear regression model:

$Renewal\ Likelihood^2 = \beta_0 +\ \beta_1\ memory\ score + \beta_2\ age\ bucket\ [35-50] + \beta_3\ age\ bucket\ [>50]$

```{r, message = F , warning=F, fig.cap="Table 5: Linear regression summary results."}
#y: renewal likelihood
#x: memory score, age buckets, gender, page time, buffer performance

reg_1 = lm((Renewal.Liklihood_1)^2 ~ memory_score + label + page_time + buffer_count, data = mat_retention_fin_1)

reg_1 = lm((Renewal.Liklihood_1)^2 ~ memory_score + age_bucket, data = filter(mat_retention_fin_1, label != "Reduced List"))

reg_1 = lm((Renewal.Liklihood_1)^2 ~ memory_score + age_bucket + Gender, 
           data = filter(mat_retention_fin_1, Gender == "Female" | Gender == "Male")) #add gender var (no effect)

reg_1 = lm((Renewal.Liklihood_1)^2 ~ memory_score + age_bucket, data = mat_retention_fin_1) #selected model

tab_model(reg_1, show.ci = F, show.stat = T, show.se = T)
```

Table 5: Linear regression summary results.

```{r, message = F , warning=F, fig.cap="Figure 11: Scatterplot of residuals and fitted values & QQ plot to test constant variance and normality assumptions for the linear regression model."}
par(mfrow = c(1,2))

plot(reg_1, which = 1:2) #constant var (mean zero), normal dist
```

```{r, message = F , warning=F, include=F}
x = mat_retention_fin_1 %>%  dplyr::select(Renewal.Liklihood_1, memory_score, page_time, buffer_count)
#cor(x, method = "pearson", use = "complete.obs") #multicollinearity check

#ppl more likely to renew when they remember
```

OLS Assumptions hold and there is a statistically significant relationship (at the 10% level) between benefit memory retention and squared renewal likelihood when controlling for age groups.

**Limitations**

1. The study is limited to the online environment of general sports fans (not season ticket holders let alone hockey season ticket holders). Therefore, our subject pool is not entirely representative of the NHL season ticket holder population.

2. Given that our subjects were not guaranteed hockey fans, they may have struggled to understand some of the benefits offered and this gap in understanding could have impacted their benefit recollection.

**Main Findings**

1. There is a positive and statistically significant (10%) relationship between renewal likelihood and memory. This suggests that individuals who remember the season ticket benefits more are more likely to renew their season tickets.

2. No significant treatment effects for memory nor renewal likelihood were found.

3. Participants spent less time on the screen in the reduced condition, but remembered the same number of benefits as the control and other treatment conditions, on average.

4. We would suggest that clearly communicating season ticket benefits to current holders plays a role in their likelihood to renew. Given that people don't spend a considerable amount of time going through their emails, its crucial to clearly display the benefits to enhance individual's memory retention. 

```{r,include=F}
#### Miscellaneous: Summary Stats & Payments

#Summary Stats: Requested by the professor

#```{r, message = F , warning=F}
#mat_retention_fin_1 %>%
#  group_by(label) %>%
#  summarise(mean_memory = mean(memory_score)) %>%
#  arrange(-mean_memory)

#mat_retention_fin_1 %>%
#  group_by(label) %>%
#  summarise(mean_renewal = mean(Renewal.Liklihood_1)) %>%
#  arrange(-mean_renewal)
#```

#Payments: Monetary payments to participants

#```{r}
#df_payments = cbind(MTurkID = df_1$MTurkID, Payment = mat_retention_fin_pre$user_payment) %>% 
#  data.frame() %>% arrange(MTurkID)

#write.csv(df_payments, "qualtrics_payments.csv")
```


